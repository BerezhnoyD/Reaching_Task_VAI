{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d363a9d3",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# ReachOut - reaching movement kinematics analysis\n",
    "___\n",
    "\n",
    "## This is the Notebook containing all the steps to prepare the video for analysis with DEEPLABCUT and Anipose and then segment and vizualize the trajectories:\n",
    "\n",
    "### 0. Cut the video from the FLIR camera into three parts - three different views of the reach\n",
    "We are recording the videos of the reaching task using the single high speed widefield FLIR camera and multiple mirrors, an then cut the single video into parts corresponding to the Leftside view (CamA), Center view (CamB), Rightside view (CamC). This eliminates the need for synchronisation of different videos, but adds this additional step before we can analyze our videos with DLC. \n",
    "As a result of this step you should get three video files with the names -camA, -camB, -camC \n",
    "\n",
    "### 1. Analyze the video with DeepLabCut\n",
    "This step is done using the open-source DEEPLABCUT and Anipose packages, so the tutorial and more info on them can be found on GitHub\n",
    "__[https://github.com/DeepLabCut](DEEPLABCUT)__\n",
    "\n",
    "It should be further noted that despite the Anipose documentation advice to use single DLC network for all views we found that better results are achieved with two separate networks trained on the side(1) and front(2) view. That means we start DLC analysis for our videos twice - first time for all the CamA/C videos, and the second time for CamB.\n",
    "As a result we get two separate sets of _*.csv *.h5_ files. For the next step they should be copied together to the Anipose folder\n",
    "\n",
    "### 2. Triangulate the 2d trajectories with Anipose \n",
    "This step is done using the open-source Anipose package, so the tutorial and more info on them can be found on GitHub\n",
    "__[https://github.com/lambdaloop/anipose](ANIPOSE)__\n",
    "\n",
    "To get use of Anipose triangulation we manually put the resulting .csv and .h5 files into anipose project folder _*/Anipose project/pose-2d before_ before starting the triangulation command _anipose triangulate_\n",
    "\n",
    "As a result of this step you should get the single _*.csv_ file for each session, containing the x,y,z coordinates that we will use further  \n",
    "\n",
    "### 3. Open the csv file, scroll through the trajectories and manually choose the fragments of the trajectory with the reaches for analysis\n",
    "\n",
    "As a result of this step you will have the _*.h5_ file with the fragments of the trajectory that you've chosen. Open this file to review the trajectories.  \n",
    "\n",
    "### 4. Open the h5 file and the corresponding video to review and classify the trajectories\n",
    "\n",
    "For this script to work point it to the _*.h5_ file you want to analyze (file) and the video corresponding to the same session (file2)\n",
    "As a result of this step you will have the _*.h5_ file which is used in the vizualisation steps 5. and 6.\n",
    "\n",
    "### 5. Open the scalars.h5 file and plot all the trajectories of the chosen category\n",
    "\n",
    "### 6. Open the scalars.h5 file and make violin plots for the chosen parameters and reach categories  \n",
    "  \n",
    "  \n",
    "  ***\n",
    "  ___\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f5c4e4",
   "metadata": {},
   "source": [
    "# Analysis part\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1160162",
   "metadata": {},
   "source": [
    "#### 0. Cut the video from the FLIR camera \n",
    "Note that we have two scripts for two use cases. If you need to process just a single file, type _from video_split import video_split_ and if you want to process all files in a certain folder type _from video_split_folder import video_split_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5752cc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to do bulk analysis on all the files in a folder - uncomment the second line and comment the first one \n",
    "#from video_split import video_split           #for single file\n",
    "from video_split_folder import video_split    #for multiple files\n",
    "\n",
    "video_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcace58",
   "metadata": {},
   "source": [
    "#### 1.  Analyze the video with DeepLabCut\n",
    "The following line should open DLC interface. Open the project containing your trained network, open the analyze video layout and select the videos you want to track (supposedly, either all camA, camB, or camC videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3dfdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplabcut\n",
    "deeplabcut.launch_dlc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d199b5",
   "metadata": {},
   "source": [
    "#### 2. Triangulate the 2d trajectories with Anipose \n",
    "By now this is done outside of the jupyter notebook, because you need to perform several steps, not including the Anipose calibration: <ol> <li>-  manually make an Anipose directory </li>  <li>-  rename the files after DLC analysis, leaving just the *camX* in the end </li> <li>- transfer the .csv and .h5 files with the tracking results to the Anipose directory </li> <li>- *cd* to this directory and </li> <li>- run from the command prompt *anipose triangulate* </li> </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b214af72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0e6cf3c",
   "metadata": {},
   "source": [
    "#### 3. Open the csv file, scroll through the trajectories\n",
    "\n",
    "The following program snippet allows you to open the csv file with Anipose output and scroll through the traejctories, visualizing them as a 3d plot + 2 projections: to X and Y axis. \n",
    "**Scroll** by moving the slider at the very bottom. **The 3d plot can be rotated** by howering on top of it with the mouse and holding left button.\n",
    "Also when you move your mouse to the left lower X-projection plot and hold the left button you can choose the smaller part of the trajectory to visualize with a **span selector**. \n",
    "If after close inspection you find this part of the trajectory useful for further analysis (it looks like a valid reach or any other action you are after), you should press the left **Save button** to add it to the resulting output table.\n",
    "The **Save_all button** on the right saves the resulting table with all the parameters as a *.h5* file for further analysis.\n",
    "\n",
    "The parameters calculated and added to the table at this step:\n",
    "* dX\n",
    "* dY\n",
    "* dZ\n",
    "* dE\n",
    "* time_difference\n",
    "* velocity\n",
    "* acceleration\n",
    "* jerk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8ce6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# for more dynamic programs like this one we are switching to the interactive matplotlib backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5b52a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb83f4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tracking_split\n",
    "tracking = tracking_split.TrackingViewer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cd97d4",
   "metadata": {},
   "source": [
    "#### 4. Open the h5 file and the corresponding video to review and classify the trajectories\n",
    "The following program opens the file with all the trajectories saved on the previous step, along with the video file **(the path to both should be typed in the following cell)**\n",
    "Left dropdown list shows all the reaches with the corresponding frames in a video. As soon as you choose one the popup window will show the corresponding part of the video. To **close the window** type Q on the keyboard. After inspecting the video an accompanying plots **mark the reach** with one of the categories on the right. By default all the reaches are marked as Missed or the last chosen option in the **right list**. As soon as you click on one of the options, the label for the current reach gets updated. When you finish **click Save** to write down the changes to the file. The file is saved with the same name as the input file with added *_scalar.h5* suffix and used in all the visualization steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5876024",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "# for more static programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3640de67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import viewer\n",
    "directory = 'C:/Users/daniil.berezhnoi.VAI/Videos/3d plot - manual assembly/NCB1019/'\n",
    "filename = 'mj_17_18_10_ncb1019.mp4'\n",
    "filename2 = '12ncb1019.h5'\n",
    "file = directory+filename\n",
    "file2 = directory+filename2\n",
    "\n",
    "view = viewer.ReachesViewer(file, file2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b632c6",
   "metadata": {},
   "source": [
    "# Visualization part\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df31152",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fdd06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook  \n",
    "# for interactive programs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af0ebba",
   "metadata": {},
   "source": [
    "#### 5. Open the scalars.h5 file and plot all the trajectories of the chosen category\n",
    "This snippet shows all reaches in the chosen category as Timeseries for visual inspection and analysis. From the lists you can choose the category of reaches and the type of data to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ba9fe3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import reach_view\n",
    "viewer = reach_view.TimeSeriesViewer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb0cf6b",
   "metadata": {},
   "source": [
    "#### 6. Open the scalars.h5 file and make violin plots for the chosen parameters and reach categories\n",
    "This snippet shows all the calculated parameters for all reaches in the current session in the form of violin plots. \n",
    "The categories to show can be chosen from the left list **(Shift/Ctrl+Click for multiple choise)** and parameters - from the right list.\n",
    "**Left plot** represents mean for the chosen parameter for every reach (data points).\n",
    "**Right plot** represents variance for the chosen parameter for every reach (data points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3661400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scalar_view\n",
    "viewer = scalar_view.InteractiveScalarViewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8fca53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af22ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DEEPLABCUT] *",
   "language": "python",
   "name": "conda-env-DEEPLABCUT-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
